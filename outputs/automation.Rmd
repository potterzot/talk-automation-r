---
title: "Let's Get Loopy!"
author: "Nicholas A Potter"
date: "10/16/2019"
output: 
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Before we start:

The following packages are needed to reproduce the code below:

- `here`
- `dplyr`
- `tidyr`
- `purrr`
- `furrr`
- `broom`
- `parallel`
- `data.table`

Install them all with `install.packages(c("here", "dplyr", "tidyr", "purrr", "furrr", "broom", "parallel", "data.table"))`.

## Basic Principle: Keep your code DRY (Don't Repeat Yourself)

#### Reduce frustration and errors by following these key ideas:
- Use loops to reduce chance of errors
- Limit loops to data that has the same format
- Write the interior of the loop first for a single case
- Loop for a small subset while developing
- Write checks for the data afterward

#### Options
- `for` loops `for (i in 1:n) { ... }`
- `apply`, `tapply`, `sapply`, `lapply`
- parrallel computing: `mclapply`
- `Reduce` and `Map`
- `purrr:reduce` and `purrr::map` [link](https://purrr.tidyverse.org/)
- `furrr:map` [link](https://davisvaughan.github.io/furrr/)

## Differences


## Looping with `apply`, `lapply`, `tapply`

`apply` applies a function to a dimension of data
```{r}
# if d is a three dimensional dataset
d <- array(rnorm(24), dim = c(3,2,4))

d1 <- apply(d, c(1,2), mean)

grid <- expand.grid(x <- row.names(d), y = colnames(d))

```



## Looping over multiple files: load - combine - clean

Often you have many files, as we have in the `data` directory of this repository.

```{r}
library(here)
files <- list.files(here("data"))
```

### Load

We could load each of them and then append:

```{r}
# ... so boring ... and so error prone ...
d1 <- readRDS(here("data", files[[1]]))
d2 <- readRDS(here("data", files[[2]]))
d2 <- readRDS(here("data", files[[3]]))
d3 <- readRDS(here("data", files[[4]]))
d4 <- readRDS(here("data", files[[5]]))
d5 <- readRDS(here("data", files[[6]]))

# d <- Reduce(rbind, list(d1, d2, d3, d4, d5))
```

Instead you can iterate over the files and read them in:

```{r}
# Using a for loop
d_list <- list()
for (i in seq_along(files)) {
  d_list[[i]] <- readRDS(here("data", files[[i]]))
}

# Using lapply
d_list <- lapply(files, function(f) {
  dtmp <- readRDS(here("data", f))
  dtmp$name <- f
  # You can do a lot of data processing here
})

lapply(files, function(f) {
  print(f)
})

str(d_list[[1]])
sapply(d_list[[1]], typeof)

# Using mclapply
library(parallel)
mc <- getOption("mc.cores", 4)
d_list <- mclapply(files, function(f) {
  readRDS(here("data", f))
  # You can do a lot of data processing here
})
```

### Comine 

Combine the data into a single data.frame:

```{r}
# Using Reduce
d <- Reduce(rbind, d_list)

# Using data.table
d <- data.table::rbindlist(d_list, fill = TRUE)

# Using dplyr
d <- dplyr::bind_rows(d_list)

# Using purrr
d <- purrr::map_dfr(d_list, ~ .)

# Parallel
d_wa <- furrr::future_map_dfr(d_list, ~ filter(., state_alpha == "WA"))

```

### Clean

Then we can tidy the data. We only need a few things:
- unit of observation (county)
- time of observation (year)
- variable
- value

But `Value` is a messy variable:

```{r}
sort(unique(d$Value)) %>% head()
```

```{r}
head(d)

library(dplyr)
library(tidyr)
d_tdy <- d %>%
  # Just the columns we want
  select(state_alpha, state_fips_code, county_code, year, variable, Value) %>%
  # Keep just the census variables
  filter(year %in% seq(1997,2017, by = 5)) %>%
  # Create a `fips` column that is the unit of observation identifier
  unite(fips, state_fips_code, county_code, sep = "") %>%
  # Clean the `Value` column to be numeric
  mutate(value = trimws(gsub(",", "", Value)),
         value = gsub("(Z)|(D)", NA, value),
         value = as.numeric(value)) %>%
  # Fix multiple observations for a given fips-year combination
  group_by(state_alpha, fips, year, variable) %>%
  summarize(value = sum(value, na.rm = TRUE)) %>%
  # Give each value in `variable` it's own column
  spread(key = variable, value = value) %>%
  # remove the grouping
  ungroup()
```

## Looping over multiple files: load - clean - combine

We could switch the order of things to clean each data set as we read it in. I personally prefer the first option if possible. It is faster, but sometimes you have to do some cleaning that is specific to a certain file.

__Reasons to use the load - clean - combine ordering__

- The combined data is too big to be read into memory without subsetting/cleaning first.
- Data has to be handled differently based on file, use `if(f == ...) { ... } else if(...) { ... } else { ... }` to handle, or use different read loops to group files that are formatted the same.


```{r}
d_list2 <- lapply(files, function(f) {
  d <- readRDS(here("data", f)) %>%
    # Keep just the census variables
    filter(year %in% seq(1997,2017, by = 5))

  if(nrow(d) > 0) {
    d_tdy <- d %>%
      # Just the columns we want
      select(state_alpha, state_fips_code, county_code, year, variable, Value) %>%
      # Create a `fips` column that is the unit of observation identifier
      unite(fips, state_fips_code, county_code, sep = "") %>%
      # Clean the `Value` column to be numeric
      mutate(value = trimws(gsub(",", "", Value)),
             value = gsub("(Z)|(D)", NA, value),
             value = as.numeric(value)) %>%
      # Fix multiple observations for a given fips-year combination
      group_by(state_alpha, fips, year, variable) %>%
      summarize(value = sum(value, na.rm = TRUE)) %>%
      # Give each value in `variable` it's own column
      spread(key = variable, value = value) %>%
      # remove the grouping
      ungroup()
  } else {
    d_tdy <- data.frame()
  }

  d_tdy
})

# CAREFUL! Don't rbind because we've already transformed the data, so we have to merge instead
d <- Reduce(function(x,y) { merge(x,y, by = c("state_alpha", "fips", "year"), all.x = TRUE) }, d_list2)
```

## Looping for analysis

We can regress data here using a model, something like

```{r}
# Let's see if there's a relationship between farm profits per acre and ownership rates
d2 <- d_tdy %>%
  mutate(farms = farms_fullown + farms_partown + farms_tenant,
         ag_expenses = expense_chem + expense_fert + expense_fuel + 
                       expense_hired + expense_seeds,
         profit_per_farm = (ag_sales - ag_expenses) / farms,
         farms_rented_pct = farms_tenant / farms)
# Note that the standard errors here won't be right because there is likely spatial and temporal correlation
d_west <- d2 %>%
  filter(state_alpha %in% c("WA", "OR", "ID", "MT", "CA", "AZ", "NV", "UT", "NM", "CO", "WY"))
m <- lm(farms_rented_pct ~ profit_per_farm + fips + state_alpha:year, data = d_west)
summary(m)
```

Often we want to run a number of regression models and output the results as a list

```{r}
## Loop over deciles
dsub1 <- d_west %>% filter(ntile(d_west$profit_per_farm, 10) == 1)
m1 <- lm(farms_rented_pct ~ profit_per_farm + fips + state_alpha:year, data = dsub1)

dsub2 <- d_west %>% filter(ntile(d_west$profit_per_farm, 10) == 2)
m2 <- lm(farms_rented_pct ~ profit_per_farm + fips + state_alpha:year, data = dsub2)

dsub3 <- d_west %>% filter(ntile(d_west$profit_per_farm, 10) == 3)
m3 <- lm(farms_rented_pct ~ profit_per_farm + fips + state_alpha:year, data = dsub3)

# Using lapply
result_list <- lapply(1:10, function(i) {
  dsub <- d_west %>% filter(ntile(d_west$profit_per_farm, 10) == i)
  m <- lm(farms_rented_pct ~ profit_per_farm + fips + state_alpha:year, data = dsub)
  # Could be: glm, lfe, plm, nlme4
  m
})
names(result_list) <- paste0("dec_", 1:10)

# Using different model specifications
result_list <- list()
for(m in models) {
  key <- paste("profit_only")
  result_list[[key]] <- lm(farms_rented_pct ~ profit_per_farm, data = dsub)
  
  key <- paste("profit_fips")
  result_list[[key]] <- lm(farms_rented_pct ~ profit_per_farm + fips, data = dsub)
}


# Or with purrr
result_list <- d_west %>%
  mutate(decile = ntile(.$profit_per_farm, 10)) %>%
  split(.$decile) %>%
  map(~ lm(farms_rented_pct ~ profit_per_farm + fips + state_alpha:year, data = .))

```

And we can also loop to extract coefficients and summary statistics
```{r}
library(broom)
library(purrr)

# Coefficients
coef_list <- lapply(seq_along(result_list), function(i) {
  coefs <- tidy(result_list[[i]])
  coefs$model <- paste0("dec_", i)
  coefs
})
coefs <- bind_rows(coef_list)

# Summary Stats
stat_list <- lapply(result_list, function(r) {
  glance(r)
})
names(stat_list) <- paste0("dec_", 1:10)
sumstats <- bind_rows(stat_list)
sumstats <- Reduce(rbind, stat_list)
sumstats <- rbindlist(stat_list)


filter(sumstats, AIC == pmin(AIC))
```


```{r}
regress <- function(d, y_var, x_vars) {
  f <- as.formula(paste0(y_var, " ~ ", paste0(x_vars, collapse = " + ")))
  lm(f, d)
}

# x_vars <- list of all variables
# x_interacts <- list of all interactions

for(seq_along(x_vars)) {
  regress(d, y_var, x_vars[i])
}

```
